<!-- GETTING STARTED -->

## Getting Started

Clone the repository into a local machine using

```sh
git clone https://github.com/murilobiss/Data-Pipelines-Airflow
```

### Prerequisites

These are the prerequisites to run the program.

* python 3.7
* AWS account
* Apache Airflow

### How to run

Follow the steps to extract and load the data into the data model.

1. Set up Apache Airflow to run in local
2. Navigate to `Data-Pipelines-Airflow` folder
3. Set up `AWS Connection` and `Redshift Connection` to Airflow using necessary values
4. In Airflow, turn the DAG execution ON
5. View the Web UI for detailed insights about the operation

